{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    " - Imprt main libraries\n",
    " - Load and Save Files\n",
    " - Running Simulations\n",
    " - MFI algorithms\n",
    " - Integraiton in 1D\n",
    " - Integration in 2D\n",
    " - Calculate Error\n",
    " - Other Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import statistics\n",
    "import scipy.integrate as integrate\n",
    "import plumed\n",
    "import pandas as pd\n",
    "from labellines import labelLines\n",
    "from labellines import labelLine\n",
    "import scipy.io\n",
    "import matplotlib as mpl\n",
    "\n",
    "from matplotlib import rc\n",
    "plt.rcParams.update({ \"text.usetex\": True, \"font.family\": \"serif\", \"font.serif\": [\"computer modern roman\"], \"font.size\": 14})\n",
    "plw = 0.6\n",
    "pcs = 3\n",
    "pms = 3\n",
    "bfillc = [0.9,0.9,0.9]\n",
    "plt.rcParams['axes.linewidth'] = plw\n",
    "plt.rcParams['xtick.top'] = True\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['xtick.major.width'] = plw\n",
    "plt.rcParams['xtick.minor.width'] = plw\n",
    "plt.rcParams['xtick.minor.visible'] = True\n",
    "plt.rcParams['xtick.major.size'] = 4.5\n",
    "plt.rcParams['ytick.right'] = True\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "plt.rcParams['ytick.major.width'] = plw\n",
    "plt.rcParams['ytick.minor.width'] = plw\n",
    "plt.rcParams['ytick.minor.visible'] = True\n",
    "plt.rcParams['ytick.major.size'] = 5\n",
    "plt.rcParams[\"figure.figsize\"] = (5,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Save Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the HILLS data\n",
    "def load_HILLS_1D(hills_name = \"HILLS\"):\n",
    "    for file in glob.glob(hills_name):\n",
    "        hills = np.loadtxt(file)\n",
    "        hills = np.concatenate(([hills[0]], hills[:-1]))\n",
    "        hills[0][3] = 0\n",
    "    return hills\n",
    "\n",
    "#Load the trajectory (position) data\n",
    "def laod_position_1D(position_name = \"position\"):\n",
    "    for file1 in glob.glob(position_name):\n",
    "        colvar = np.loadtxt(file1)\n",
    "    return colvar[:-1, 1]\n",
    "\n",
    "def laod_positiontime_1D(position_name = \"position\"):\n",
    "    for file1 in glob.glob(position_name):\n",
    "        colvar = np.loadtxt(file1)\n",
    "        time = colvar[:-1, 0]\n",
    "    return time\n",
    "\n",
    "def load_HILLS_2D(hills_name = \"HILLS\"):\n",
    "    for file in glob.glob(hills_name):\n",
    "        hills = np.loadtxt(file)\n",
    "        hills = np.concatenate(([hills[0]], hills[:-1]))\n",
    "        hills[0][5] = 0\n",
    "    return hills\n",
    "\n",
    "def laod_position_2D(position_name = \"position\"):\n",
    "    for file1 in glob.glob(position_name):\n",
    "        colvar = np.loadtxt(file1)\n",
    "        position_x = colvar[:-1, 1]\n",
    "        position_y = colvar[:-1, 2]\n",
    "    return [position_x, position_y]\n",
    "\n",
    "##################################################################\n",
    "\n",
    "def save_pkl(object, file_name):\n",
    "    with open(file_name, \"wb\") as fw:\n",
    "        pickle.dump(object, fw, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_pkl(name):\n",
    "    with open(name, \"rb\") as fr:\n",
    "        return pickle.load(fr)\n",
    "\n",
    "def save_npy(object, file_name):\n",
    "    with open(file_name, \"wb\") as fw:\n",
    "        np.save(fw, object)\n",
    "\n",
    "def load_npy(name):\n",
    "    with open(name, \"rb\") as fr:\n",
    "        return np.load(fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runing Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run a 1D Langevin simulation using the analytical force field y=7*x^4-23*x^2\n",
    "### Produces a position file that contains the CV value over time, a HILLS\n",
    "### file that contains informaton on the history dependet bias, a histo file that \n",
    "### contains the histogram of the CV value and a fes.dat file that contains the FES.\n",
    "\n",
    "def run_langevin1D_plumed_fes(length, fes_stride=0, sigma=0.1, height=0.1, biasfactor=10):\n",
    "    with open(\"plumed.dat\",\"w\") as f:\n",
    "        print(\"\"\"#Define system as distance between two atoms\n",
    "p: DISTANCE ATOMS=1,2 COMPONENTS\n",
    "#Define Force field\n",
    "ff: MATHEVAL ARG=p.x PERIODIC=NO FUNC=(7*x^4-23*x^2)\n",
    "bb: BIASVALUE ARG=ff\n",
    "#Define Histroy dependet bias potentail (baisfactor very large so that height stays constant)\n",
    "# METAD ARG=p.x PACE=100 SIGMA=0.1 HEIGHT=0.1 TEMP=120 BIASFACTOR=10000\n",
    "METAD ARG=p.x PACE=100 SIGMA={} HEIGHT={} GRID_MIN=-3 GRID_MAX=3 GRID_BIN=600 BIASFACTOR={} TEMP=120 CALC_RCT\n",
    "#Reweight Bias\n",
    "bias: REWEIGHT_METAD TEMP=120\n",
    "#Make Histogram\n",
    "hh: HISTOGRAM ARG=p.x GRID_MIN=-3 GRID_MAX=3 GRID_BIN=600 BANDWIDTH=0.01 LOGWEIGHTS=bias\n",
    "#Convert Histogram to FES\n",
    "fes: CONVERT_TO_FES GRID=hh TEMP=120\n",
    "#Save Histogram and FES at the end. Save position every 10 time-steps    \n",
    "#DUMPGRID GRID=hh FILE=histo STRIDE={}\n",
    "DUMPGRID GRID=fes FILE=fes.dat STRIDE={}\n",
    "PRINT FILE=position ARG=p.x STRIDE=10\"\"\".format(sigma, height, biasfactor, fes_stride, fes_stride),file=f)\n",
    "\n",
    "    with open(\"input\",\"w\") as f:\n",
    "        print(\"\"\"temperature 1\n",
    "tstep 0.005\n",
    "friction 1\n",
    "dimension 1\n",
    "nstep {}\n",
    "ipos -1.0\n",
    "periodic false\"\"\".format(length),file=f)\n",
    "\n",
    "    #Start WT-Metadynamic simulation\n",
    "    !plumed pesmd < input\n",
    "    \n",
    "    \n",
    "#Runnig simulation with the intention to alanyse the results with MFI works the same  \n",
    "#way as for metadynamcis and WT-metadynamics, but one doesnt need to do the reweighting  \n",
    "#or calculate the histogram, just save the trajectory and the HILLS. \n",
    "\n",
    "def run_langevin1D(length, sigma=0.1, height=0.1, biasfactor=10):\n",
    "    with open(\"plumed.dat\",\"w\") as f:\n",
    "        print(\"\"\"p: DISTANCE ATOMS=1,2 COMPONENTS\n",
    "ff: MATHEVAL ARG=p.x PERIODIC=NO FUNC=(7*x^4-23*x^2)\n",
    "bb: BIASVALUE ARG=ff\n",
    "METAD ARG=p.x PACE=100 SIGMA={} HEIGHT={} GRID_MIN=-3 GRID_MAX=3 GRID_BIN=200 BIASFACTOR={} TEMP=120\n",
    "PRINT FILE=position ARG=p.x STRIDE=10\"\"\".format(sigma,height, biasfactor),file=f)\n",
    "\n",
    "    with open(\"input\",\"w\") as f:\n",
    "        print(\"\"\"temperature 1\n",
    "tstep 0.005\n",
    "friction 1\n",
    "dimension 1\n",
    "nstep {}\n",
    "ipos -1.0\n",
    "periodic false\"\"\".format(length),file=f)\n",
    "    \n",
    "    !plumed pesmd < input\n",
    "    \n",
    "    \n",
    "#Run Metadynamics with umbrella sampling in 1D\n",
    "def run_langevin1D_hp(sim_len, kappa, hp_pos, sigma = 0.1, height = 1, biasfactor = 10):\n",
    "    with open(\"plumed.dat\",\"w\") as f:\n",
    "        print(\"\"\"p: DISTANCE ATOMS=1,2 COMPONENTS\n",
    "ff: MATHEVAL ARG=p.x PERIODIC=NO FUNC=(7*x^4-23*x^2)\n",
    "bb: BIASVALUE ARG=ff\n",
    "RESTRAINT ARG=p.x AT={} KAPPA={} LABEL=restraint\n",
    "METAD ARG=p.x PACE=100 SIGMA={} HEIGHT={} GRID_MIN=-3 GRID_MAX=3 GRID_BIN=300 BIASFACTOR={} TEMP=120 CALC_RCT\n",
    "PRINT FILE=position ARG=p.x STRIDE=10\n",
    "\"\"\".format(hp_pos,kappa, sigma, height, biasfactor),file=f)\n",
    "\n",
    "    with open(\"input\",\"w\") as f:\n",
    "        print(\"\"\"temperature 1\n",
    "tstep 0.005\n",
    "friction 1\n",
    "dimension 1\n",
    "nstep {}\n",
    "ipos {}\n",
    "periodic false\"\"\".format(sim_len, hp_pos),file=f)\n",
    "        \n",
    "    #Start simulation\n",
    "    !plumed pesmd < input\n",
    "    \n",
    "############################################################################################\n",
    "\n",
    "### Run a 2D Langevin simulation using the analytical force field z=7*x^4-23*x^2 + 7*y^4-23*y^2  \n",
    "def run_langevin2D_plumed_fes(length, sigma=0.1, height=0.1, biasfactor=10):\n",
    "    with open(\"plumed.dat\",\"w\") as f:\n",
    "        print(\"\"\"p: DISTANCE ATOMS=1,2 COMPONENTS\n",
    "ff: MATHEVAL ARG=p.x,p.y PERIODIC=NO FUNC=(7*x^4-23*x^2+7*y^4-23*y^2)\n",
    "bb: BIASVALUE ARG=ff\n",
    "METAD ARG=p.x,p.y PACE=100 SIGMA={},{} HEIGHT={} GRID_MIN=-3,-3 GRID_MAX=3,3 GRID_BIN=300,300 BIASFACTOR={} TEMP=120 CALC_RCT\n",
    "bias: REWEIGHT_METAD TEMP=120\n",
    "hh: HISTOGRAM ARG=p.x,p.y GRID_MIN=-3,-3 GRID_MAX=3,3 GRID_BIN=300,300 BANDWIDTH=0.02,0.02 LOGWEIGHTS=bias\n",
    "fes: CONVERT_TO_FES GRID=hh TEMP=120\n",
    "DUMPGRID GRID=fes FILE=fes.dat STRIDE={}\n",
    "PRINT FILE=position ARG=p.x,p.y STRIDE=10\"\"\".format(sigma, sigma, height, biasfactor, length),file=f)\n",
    "\n",
    "    with open(\"input\",\"w\") as f:\n",
    "        print(\"\"\"temperature 1\n",
    "tstep 0.005\n",
    "friction 1\n",
    "dimension 2\n",
    "nstep {}\n",
    "ipos -1.0,-1.0\n",
    "periodic false\"\"\".format(length),file=f)\n",
    "\n",
    "    !plumed pesmd < input \n",
    "    \n",
    "    \n",
    "### Run a 2D Langevin simulation using the analytical force field z=7*x^4-23*x^2 + 7*y^4-23*y^2\n",
    "def run_langevin2D(length, sigma=0.1, height=0.1, biasfactor=10):\n",
    "    with open(\"plumed.dat\",\"w\") as f:\n",
    "        print(\"\"\"p: DISTANCE ATOMS=1,2 COMPONENTS\n",
    "ff: MATHEVAL ARG=p.x,p.y PERIODIC=NO FUNC=(7*x^4-23*x^2+7*y^4-23*y^2)\n",
    "bb: BIASVALUE ARG=ff\n",
    "METAD ARG=p.x,p.y PACE=100 SIGMA={},{} HEIGHT={} GRID_MIN=-3,-3 GRID_MAX=3,3 GRID_BIN=300,300 BIASFACTOR={} TEMP=120 CALC_RCT\n",
    "PRINT FILE=position ARG=p.x,p.y STRIDE=10\"\"\".format(sigma, sigma, height, biasfactor, length),file=f)\n",
    "\n",
    "    with open(\"input\",\"w\") as f:\n",
    "        print(\"\"\"temperature 1\n",
    "tstep 0.005\n",
    "friction 1\n",
    "dimension 2\n",
    "nstep {}\n",
    "ipos -1.0,-1.0\n",
    "periodic false\"\"\".format(length),file=f)\n",
    "\n",
    "    !plumed pesmd < input \n",
    "    \n",
    "    \n",
    "#Run Metadynamics with umbrella sampling in 2D    \n",
    "def run_langevin2D_hp(length, kappa, ipos_x, ipos_y, sigma = 0.1, height = 1, biasfactor = 10):\n",
    "    with open(\"plumed.dat\",\"w\") as f:\n",
    "        print(\"\"\"p: DISTANCE ATOMS=1,2 COMPONENTS\n",
    "ff: MATHEVAL ARG=p.x,p.y PERIODIC=NO FUNC=(7*x^4-23*x^2+7*y^4-23*y^2)\n",
    "bb: BIASVALUE ARG=ff\n",
    "#Define Harmonic potential\n",
    "RESTRAINT ARG=p.x,p.y AT={},{} KAPPA={},{} LABEL=restraint\n",
    "METAD ARG=p.x,p.y PACE=100 SIGMA={},{} HEIGHT={} GRID_MIN=-3,-3 GRID_MAX=3,3 GRID_BIN=300,300 BIASFACTOR={} TEMP=120 CALC_RCT\n",
    "PRINT FILE=position ARG=p.x,p.y STRIDE=10\"\"\".format(ipos_x,ipos_y,kappa,kappa, sigma, sigma, height, biasfactor),file=f)\n",
    "\n",
    "    with open(\"input\",\"w\") as f:\n",
    "        print(\"\"\"temperature 1\n",
    "tstep 0.005\n",
    "friction 1\n",
    "dimension 2\n",
    "nstep {}\n",
    "ipos 0.0,0.0\n",
    "periodic false\"\"\".format(length),file=f)\n",
    "        \n",
    "    !plumed pesmd < input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFI algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Algorithm to run 1D MFI\n",
    "\n",
    "def MFI_1D_simple():\n",
    "    #initialise force terms\n",
    "    Fbias = np.zeros(len(x));\n",
    "    Ftot_num = np.zeros(len(x));\n",
    "    Ftot_den = np.zeros(len(x));\n",
    "\n",
    "    for i in range(total_number_of_hills):\n",
    "        # Build metadynamics potential\n",
    "        s = HILLS[i, 1]  # center position of gausian\n",
    "        sigma_meta2 = HILLS[i, 2] ** 2  # width of gausian\n",
    "        gamma = HILLS[i, 4]  #scaling factor of gausian\n",
    "        height_meta = HILLS[i, 3] * ((gamma - 1) / (gamma))  # Height of Gausian\n",
    "        kernelmeta = np.exp(-0.5 * (((x - s) ** 2) / (sigma_meta2)))\n",
    "        Fbias = Fbias + height_meta * kernelmeta * ((x - s) / (sigma_meta2)) #Bias force due to Metadynamics potentials\n",
    "\n",
    "        # Estimate the biased proabability density\n",
    "        pb_t = np.zeros(len(x))\n",
    "        Fpbt = np.zeros(len(x))\n",
    "        data = position[i * stride: (i + 1) * stride] #positons of window of constant bias force.\n",
    "        for j in range(stride):\n",
    "            kernel = const * np.exp(- (x - data[j])**2 / (2*bw2) ) #probability density of 1 datapoint\n",
    "            pb_t = pb_t + kernel #probability density of window \n",
    "            Fpbt = Fpbt + kT * kernel * (x - data[j]) / bw2\n",
    "\n",
    "        # Estimate of the Mean Force\n",
    "        Ftot_den = Ftot_den + pb_t   #total probability density\n",
    "        dfds = np.divide(Fpbt, pb_t, out=np.zeros_like(Fpbt), where=pb_t != 0) + Fbias\n",
    "        Ftot_num = Ftot_num + pb_t * dfds\n",
    "        Ftot = np.divide(Ftot_num, Ftot_den, out=np.zeros_like(Ftot_num), where=Ftot_den != 0) #total force\n",
    "\n",
    "        if (i+1) % (total_number_of_hills/10) == 0:\n",
    "            print(str(i+1) + \" / \" + str(total_number_of_hills))\n",
    "            \n",
    "    return [Ftot_den, Ftot]\n",
    "\n",
    "#############################################################################################\n",
    "\n",
    "### Algorithm to run 1D MFI using a harmonic potential\n",
    "\n",
    "def MFI_1D_hp(position, HILLS, kappa, hp_pos, bw = 0.02):\n",
    "    \n",
    "    #calculate some constants\n",
    "    bw2 = bw**2\n",
    "    stride = int(len(position) / len(HILLS[:,1]))\n",
    "    const = (1 / (bw*np.sqrt(2*np.pi)*stride))\n",
    "    kT = 1\n",
    "    total_number_of_hills=len(HILLS[:,1])\n",
    "    print(\"total number of hills:\", total_number_of_hills)\n",
    "    \n",
    "    #define analytical harmonic FORCE (not energy!):\n",
    "    F_harmonic = float(kappa)*(x-float(hp_pos)) \n",
    "    \n",
    "    #initialise some force terms\n",
    "    Fbias = np.zeros(len(x));\n",
    "    Ftot_num = np.zeros(len(x));\n",
    "    Ftot_den = np.zeros(len(x));\n",
    "\n",
    "    for i in range(total_number_of_hills):\n",
    "        \n",
    "        # Build metadynamics potential\n",
    "        s = HILLS[i, 1]  # center position of gausian\n",
    "        sigma_meta2 = HILLS[i, 2] ** 2  # width of gausian\n",
    "        gamma = HILLS[i, 4]  #scaling factor of gausian\n",
    "        height_meta = HILLS[i, 3] * ((gamma - 1) / (gamma))  # Height of Gausian\n",
    "        kernelmeta = np.exp(-0.5 * (((x - s) ** 2) / (sigma_meta2)))\n",
    "        Fbias = Fbias + height_meta * kernelmeta * ((x - s) / (sigma_meta2)) #Bias force due to Metadynamics potentials\n",
    "\n",
    "        # Estimate the biased proabability density\n",
    "        pb_t = np.zeros(len(x))\n",
    "        Fpbt = np.zeros(len(x))\n",
    "        data = position[i * stride: (i + 1) * stride] #positons of window of constant bias force.\n",
    "        for j in range(stride):\n",
    "            kernel = const * np.exp(- (x - data[j])**2 / (2*bw2) ) #probability density of 1 datapoint\n",
    "            pb_t = pb_t + kernel #probability density of window \n",
    "            Fpbt = Fpbt + kT * kernel * (x - data[j]) / bw2\n",
    "\n",
    "        # Estimate of the Mean Force\n",
    "        Ftot_den = Ftot_den + pb_t   #total probability density\n",
    "        dfds = np.divide(Fpbt, pb_t, out=np.zeros_like(Fpbt), where=pb_t != 0) + Fbias - F_harmonic\n",
    "        Ftot_num = Ftot_num + pb_t * dfds\n",
    "        Ftot = np.divide(Ftot_num, Ftot_den, out=np.zeros_like(Ftot_num), where=Ftot_den != 0) #total force\n",
    "\n",
    "#         if (i+1) % (total_number_of_hills/10) == 0:\n",
    "#             print(str(i+1) + \" / \" + str(total_number_of_hills))\n",
    "           \n",
    "    return [Ftot_den, Ftot]\n",
    "\n",
    "#############################################################################################\n",
    "\n",
    "### Algorithm to run 2D MFI\n",
    "\n",
    "def MFI_2D_simple(bw=0.1):   \n",
    "    \n",
    "    bw2 = bw**2\n",
    "    # Initialize force terms\n",
    "    Fbias_x = np.zeros((nbins, nbins))\n",
    "    Fbias_y = np.zeros((nbins, nbins))\n",
    "    Ftot_num_x = np.zeros((nbins, nbins))\n",
    "    Ftot_num_y = np.zeros((nbins, nbins))\n",
    "    Ftot_den = np.zeros((nbins, nbins))\n",
    "\n",
    "    for i in range(total_number_of_hills):\n",
    "        # Build metadynamics potential\n",
    "        s_x = HILLS[i, 1]  # center x-position of gausian\n",
    "        s_y = HILLS[i, 2]  # center y-position of gausian\n",
    "        sigma_meta2_x = HILLS[i, 3] ** 2  # width of gausian\n",
    "        sigma_meta2_y = HILLS[i, 4] ** 2  # width of gausian\n",
    "        gamma = HILLS[i, 6]\n",
    "        height_meta = HILLS[i, 5] * ((gamma - 1) / (gamma))  # Height of Gausian\n",
    "\n",
    "        kernelmeta = np.exp(-0.5 * (((X - s_x) ** 2) / sigma_meta2_x + ((Y - s_y) ** 2) / sigma_meta2_y))  # potential erorr in calc. of s-s_t\n",
    "        Fbias_x = Fbias_x + height_meta * kernelmeta * ((X - s_x) / sigma_meta2_x);  ##potential erorr in calc. of s-s_t\n",
    "        Fbias_y = Fbias_y + height_meta * kernelmeta * ((Y - s_y) / sigma_meta2_y);  ##potential erorr in calc. of s-s_t\n",
    "\n",
    "        # Biased probability density component of the force\n",
    "        # Etimate the biased proabability density p_t ^ b(s)\n",
    "        pb_t = np.zeros((nbins, nbins))\n",
    "        Fpbt_x = np.zeros((nbins, nbins))\n",
    "        Fpbt_y = np.zeros((nbins, nbins))\n",
    "\n",
    "        data_x = position_x[i * stride: (i + 1) * stride]\n",
    "        data_y = position_y[i * stride: (i + 1) * stride]\n",
    "        for j in range(stride):\n",
    "            kernel = const * np.exp(- ((X - data_x[j]) ** 2 + (Y - data_y[j]) ** 2) / (2 * bw2) )\n",
    "            pb_t = pb_t + kernel;\n",
    "            Fpbt_x = Fpbt_x + kernel * (X - data_x[j]) / bw2\n",
    "            Fpbt_y = Fpbt_y + kernel * (Y - data_y[j]) / bw2\n",
    "\n",
    "        # Calculate Mean Force\n",
    "        Ftot_den = Ftot_den + pb_t;\n",
    "        # Calculate x-component of Force\n",
    "        dfds_x = np.divide(Fpbt_x * kT, pb_t, out=np.zeros_like(Fpbt_x), where=pb_t != 0) + Fbias_x\n",
    "        Ftot_num_x = Ftot_num_x + pb_t * dfds_x\n",
    "        Ftot_x = np.divide(Ftot_num_x, Ftot_den, out=np.zeros_like(Fpbt_x), where=Ftot_den != 0)\n",
    "        # Calculate y-component of Force\n",
    "        dfds_y = np.divide(Fpbt_y * kT, pb_t, out=np.zeros_like(Fpbt_y), where=pb_t != 0) + Fbias_y\n",
    "        Ftot_num_y = Ftot_num_y + pb_t * dfds_y\n",
    "        Ftot_y = np.divide(Ftot_num_y, Ftot_den, out=np.zeros_like(Fpbt_y), where=Ftot_den != 0)\n",
    "\n",
    "        if (i+1) % (total_number_of_hills/10) == 0: \n",
    "            print(str(i+1) + \" / \" + str(total_number_of_hills))\n",
    "            \n",
    "    return [Ftot_den, Ftot_x, Ftot_y]\n",
    "\n",
    "### Algorithm to run 2D MFI with harmonic potential\n",
    "\n",
    "def MFI_2D_hp(kappa, ipos_x, ipos_y, bw=0.1):\n",
    "\n",
    "    bw2 = bw**2\n",
    "    \n",
    "    # Initialize force terms\n",
    "    Fbias_x = np.zeros((nbins, nbins))\n",
    "    Fbias_y = np.zeros((nbins, nbins))\n",
    "    Ftot_num_x = np.zeros((nbins, nbins))\n",
    "    Ftot_num_y = np.zeros((nbins, nbins))\n",
    "    Ftot_den = np.zeros((nbins, nbins))\n",
    "\n",
    "    #Define Harmonic Force\n",
    "    F_harmonic_x = float(kappa)*(X-float(ipos_x)) \n",
    "    F_harmonic_y = float(kappa)*(Y-float(ipos_y)) \n",
    "\n",
    "\n",
    "    for i in range(total_number_of_hills):\n",
    "        # Build metadynamics potential\n",
    "        s_x = HILLS[i, 1]  # center x-position of gausian\n",
    "        s_y = HILLS[i, 2]  # center y-position of gausian\n",
    "        sigma_meta2_x = HILLS[i, 3] ** 2  # width of gausian\n",
    "        sigma_meta2_y = HILLS[i, 4] ** 2  # width of gausian\n",
    "        gamma = HILLS[i, 6]\n",
    "        height_meta = HILLS[i, 5] * ((gamma - 1) / (gamma))  # Height of Gausian\n",
    "\n",
    "        kernelmeta = np.exp(-0.5 * (((X - s_x) ** 2) / sigma_meta2_x + ((Y - s_y) ** 2) / sigma_meta2_y))  # potential erorr in calc. of s-s_t\n",
    "        Fbias_x = Fbias_x + height_meta * kernelmeta * ((X - s_x) / sigma_meta2_x);  ##potential erorr in calc. of s-s_t\n",
    "        Fbias_y = Fbias_y + height_meta * kernelmeta * ((Y - s_y) / sigma_meta2_y);  ##potential erorr in calc. of s-s_t\n",
    "\n",
    "        # Biased probability density component of the force\n",
    "        # Etimate the biased proabability density p_t ^ b(s)\n",
    "        pb_t = np.zeros((nbins, nbins))\n",
    "        Fpbt_x = np.zeros((nbins, nbins))\n",
    "        Fpbt_y = np.zeros((nbins, nbins))\n",
    "\n",
    "        data_x = position_x[i * stride: (i + 1) * stride]\n",
    "        data_y = position_y[i * stride: (i + 1) * stride]\n",
    "        for j in range(stride):\n",
    "            kernel = const * np.exp(- ((X - data_x[j]) ** 2 + (Y - data_y[j]) ** 2) / (2 * bw2) )\n",
    "            pb_t = pb_t + kernel;\n",
    "            Fpbt_x = Fpbt_x + kernel * (X - data_x[j]) / bw2\n",
    "            Fpbt_y = Fpbt_y + kernel * (Y - data_y[j]) / bw2\n",
    "\n",
    "        # Calculate Mean Force\n",
    "        Ftot_den = Ftot_den + pb_t;\n",
    "        # Calculate x-component of Force\n",
    "        dfds_x = np.divide(Fpbt_x * kT, pb_t, out=np.zeros_like(Fpbt_x), where=pb_t != 0) + Fbias_x - F_harmonic_x\n",
    "        Ftot_num_x = Ftot_num_x + pb_t * dfds_x\n",
    "        Ftot_x = np.divide(Ftot_num_x, Ftot_den, out=np.zeros_like(Fpbt_x), where=Ftot_den != 0)\n",
    "        # Calculate y-component of Force\n",
    "        dfds_y = np.divide(Fpbt_y * kT, pb_t, out=np.zeros_like(Fpbt_y), where=pb_t != 0) + Fbias_y - F_harmonic_y\n",
    "        Ftot_num_y = Ftot_num_y + pb_t * dfds_y\n",
    "        Ftot_y = np.divide(Ftot_num_y, Ftot_den, out=np.zeros_like(Fpbt_y), where=Ftot_den != 0)\n",
    "\n",
    "        if (i+1) % (total_number_of_hills/10) == 0: \n",
    "            print(str(i+1) + \" / \" + str(total_number_of_hills))\n",
    "            \n",
    "    return [Ftot_den, Ftot_x, Ftot_y]\n",
    "\n",
    "#############################################################################################\n",
    "\n",
    "### Patching 1D simulations \n",
    "\n",
    "def patch_1D(master_array):\n",
    "    F = np.zeros(len(master_array[0][0]))\n",
    "    F_den = np.zeros(len(master_array[0][0]))\n",
    "\n",
    "    for i in range(len(master_array)):\n",
    "        F += master_array[i][0] * master_array[i][1]\n",
    "        F_den += master_array[i][0]\n",
    "\n",
    "    F = np.divide(F, F_den, out=np.zeros_like(F), where=F_den != 0)  \n",
    "    return [F_den, F]\n",
    "\n",
    "### Patching 2D simulations \n",
    "\n",
    "def patch_2D(master_array):\n",
    "\n",
    "    FX = np.zeros((nbins, nbins))\n",
    "    FY = np.zeros((nbins, nbins))\n",
    "    FP = np.zeros((nbins, nbins))\n",
    "\n",
    "    for i in range(len(master)):\n",
    "        FX += master_array[i][0] * master_array[i][1]\n",
    "        FY += master_array[i][0] * master_array[i][2]\n",
    "        FP += master_array[i][0]\n",
    "\n",
    "    FX = np.divide(FX, FP, out=np.zeros_like(FX), where=FP != 0)\n",
    "    FY = np.divide(FY, FP, out=np.zeros_like(FY), where=FP != 0)\n",
    "    \n",
    "    return [FP, FX, FY]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Integrtion using Fast Fourier Transform (FFT integration) in 1D\n",
    "### centered around 0\n",
    "\n",
    "def FFT_intg_1D(Ftot):\n",
    "    #Fourier Transform\n",
    "    fhat = np.fft.fft(Ftot)\n",
    "    \n",
    "    #Calculate frequencyies\n",
    "    kappa = np.fft.fftfreq(nbins, grid_space) \n",
    "    kappa = np.where(kappa != 0, kappa , 1E-10)\n",
    "    \n",
    "    \n",
    "    #Integration of Fourier coefficients\n",
    "    dfhat = fhat / ( 2 * np.pi * 1j * kappa)\n",
    "    \n",
    "    #Inverse Fourier Transform\n",
    "    fes = np.real(np.fft.ifft(dfhat))\n",
    "\n",
    "    fes = fes - np.min(fes)\n",
    "    return fes ,kappa\n",
    "\n",
    "### FFT integration in 1D not centered around 0\n",
    "\n",
    "#\n",
    "\n",
    "### Integration using Simpson's methods in 1D\n",
    "\n",
    "def intg_1D(F):\n",
    "    fes = []\n",
    "    for j in range(len(x)): fes.append(integrate.simps(F[:j + 1], x[:j + 1]))\n",
    "    fes = fes - min(fes)\n",
    "    return fes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Integrtion using Fast Fourier Transform (FFT integration) in 2D\n",
    "### centered around 0\n",
    "\n",
    "def FFT_intg_2D(FX, FY):\n",
    "\n",
    "    #Calculate frequency\n",
    "    freq_1d = np.fft.fftfreq(nbins, grid_space)\n",
    "    freq_x, freq_y = np.meshgrid(freq_1d, freq_1d)\n",
    "    freq_hypot = np.hypot(freq_x, freq_y)\n",
    "    freq_sq = np.where(freq_hypot != 0, freq_hypot ** 2, 1E-10)\n",
    "    #FFTransform and integration\n",
    "    fourier_x = (np.fft.fft2(FX) * freq_x) / (2 * np.pi * 1j * freq_sq)\n",
    "    fourier_y = (np.fft.fft2(FY) * freq_y) / (2 * np.pi * 1j * freq_sq)\n",
    "    #Reverse FFT\n",
    "    fes_x = np.real(np.fft.ifft2(fourier_x))\n",
    "    fes_y = np.real(np.fft.ifft2(fourier_y))\n",
    "    #Construct whole FES\n",
    "    fes = fes_x + fes_y\n",
    "    fes = fes - np.min(fes)\n",
    "    return fes\n",
    "\n",
    "### FFT integration in 2D with option to create finer gradients using interpolation, centered around 0\n",
    "\n",
    "def FFT_intg_2D_interpolate(FX, FY, i_bins):\n",
    "\n",
    "    grid_new_x = np.linspace(grid.min(), grid.max(), i_bins[0])\n",
    "    grid_new_y = np.linspace(grid.min(), grid.max(), i_bins[1])\n",
    "    X_new, Y_new = np.meshgrid(grid_new_x, grid_new_y)\n",
    "    grid_space_x = (grid.max() - grid.min()) / (i_bins[0] - 1)\n",
    "    grid_space_y = (grid.max() - grid.min()) / (i_bins[1] - 1)\n",
    "\n",
    "    r = np.stack([X.ravel(), Y.ravel()]).T\n",
    "    Sx = interpolate.CloughTocher2DInterpolator(r, FX.ravel())\n",
    "    Sy = interpolate.CloughTocher2DInterpolator(r, FY.ravel())\n",
    "    ri = np.stack([X_new.ravel(), Y_new.ravel()]).T\n",
    "\n",
    "    FX = Sx(ri).reshape(X_new.shape)\n",
    "    FY = Sy(ri).reshape(Y_new.shape)\n",
    "\n",
    "    freq_1d_x = np.fft.fftfreq(i_bins[0], grid_space_x)\n",
    "    freq_1d_y = np.fft.fftfreq(i_bins[1], grid_space_y)\n",
    "    freq_x, freq_y = np.meshgrid(freq_1d_x, freq_1d_y)\n",
    "\n",
    "\n",
    "    freq_hypot = np.hypot(freq_x, freq_y)\n",
    "    freq_sq = np.where(freq_hypot != 0, freq_hypot ** 2, 1E-10)\n",
    "\n",
    "    fourier_x = (np.fft.fft2(FX) * freq_x) / (2 * np.pi * 1j * freq_sq)\n",
    "    fes_x = np.real(np.fft.ifft2(fourier_x))\n",
    "\n",
    "    fourier_y = (np.fft.fft2(FY) * freq_y) / (2 * np.pi * 1j * freq_sq)\n",
    "    fes_y = np.real(np.fft.ifft2(fourier_y))\n",
    "\n",
    "    fes = fes_x + fes_y\n",
    "    fes = fes - np.min(fes)\n",
    "\n",
    "    return (X_new, Y_new, fes)\n",
    "\n",
    "\n",
    "### FFT integration in 2D not centered around 0\n",
    "\n",
    "def FFT_intg_2D_nz(FX, FY):\n",
    "\n",
    "    freq_1d = np.fft.fftfreq(nbins, grid_space)\n",
    "    freq_x, freq_y = np.meshgrid(freq_1d, freq_1d)\n",
    "\n",
    "    freq_hypot = np.hypot(freq_x, freq_y)\n",
    "    freq_sq = np.where(freq_hypot != 0, freq_hypot ** 2, 1E-10)\n",
    "\n",
    "    fourier_x = (np.fft.fft2(FX) * freq_x) / (2 * np.pi * 1j * freq_sq)\n",
    "    fes_x = np.real(np.fft.ifft2(fourier_x))\n",
    "\n",
    "    fourier_y = (np.fft.fft2(FY) * freq_y) / (2 * np.pi * 1j * freq_sq)\n",
    "    fes_y = np.real(np.fft.ifft2(fourier_y))\n",
    "\n",
    "    fes = fes_x + fes_y\n",
    "    fes = fes - np.min(fes)\n",
    "\n",
    "    return fes\n",
    "\n",
    "### 2D Finite difference method\n",
    "### First integrating along x-axis with y=y_min, then integrating along y-axis\n",
    "\n",
    "def intg_FD(FX, FY):\n",
    "    SdZx = np.cumsum(FX, axis=1) * grid_space  # cumulative sum along x-axis\n",
    "    SdZy = np.cumsum(FY, axis=0) * grid_space  # cumulative sum along y-axis\n",
    "    \n",
    "    FES = np.zeros((nbins,nbins))\n",
    "    \n",
    "    for i in range(FES.shape[0]):\n",
    "        for j in range(FES.shape[1]):\n",
    "            FES[i, j]  += np.sum([SdZy[i, 0], -SdZy[0, 0], SdZx[i, j], -SdZx[i, 0]])\n",
    "            \n",
    "    \n",
    "    FES = FES - np.min(FES)\n",
    "    return FES\n",
    "\n",
    "### Extensive 2D Finite difference method\n",
    "### integrating along x-axis with y=y_min, then integrating along y-axis\n",
    "### then integrating along  x-axis with y=y_max, then integrating along y-axis\n",
    "### and repeating all posible integration paths (8 in total) \n",
    "### and finally taking the average of all integrals.\n",
    "\n",
    "\n",
    "def intg_FD8(FX,FY):\n",
    "\n",
    "    SdZx = np.cumsum(FX, axis=1) * grid_space  # cumulative sum along x-axis\n",
    "    SdZy = np.cumsum(FY, axis=0) * grid_space  # cumulative sum along y-axis\n",
    "    SdZx3 = np.cumsum(FX[::-1], axis=1) * grid_space  # cumulative sum along x-axis\n",
    "    SdZy3 = np.cumsum(FY[::-1], axis=0) * grid_space  # cumulative sum along y-axis\n",
    "    SdZx5 = np.cumsum(FX[:, ::-1], axis=1) * grid_space  # cumulative sum along x-axis\n",
    "    SdZy5 = np.cumsum(FY[:, ::-1], axis=0) * grid_space  # cumulative sum along y-axis\n",
    "    SdZx7 = np.cumsum(FX[::-1, ::-1], axis=1) * grid_space  # cumulative sum along x-axis\n",
    "    SdZy7 = np.cumsum(FY[::-1, ::-1], axis=0) * grid_space  # cumulative sum along y-axis\n",
    "\n",
    "\n",
    "    FES = np.zeros(i_bins)\n",
    "    FES2 = np.zeros(i_bins)\n",
    "    FES3 = np.zeros(i_bins)\n",
    "    FES4 = np.zeros(i_bins)\n",
    "    FES5 = np.zeros(i_bins)\n",
    "    FES6 = np.zeros(i_bins)\n",
    "    FES7 = np.zeros(i_bins)\n",
    "    FES8 = np.zeros(i_bins)\n",
    "\n",
    "    for i in range(FES.shape[0]):\n",
    "        for j in range(FES.shape[1]):\n",
    "            FES[i, j]  += np.sum([SdZy[i, 0], -SdZy[0, 0], SdZx[i, j], -SdZx[i, 0]])\n",
    "            FES2[i, j] += np.sum([SdZx[0, j], -SdZx[0, 0], SdZy[i, j], -SdZy[0, j]])\n",
    "            FES3[i, j] += np.sum([-SdZy3[i, 0], SdZy3[0, 0], SdZx3[i, j], -SdZx3[i, 0]])\n",
    "            FES4[i, j] += np.sum([SdZx3[0, j], -SdZx3[0, 0], -SdZy3[i, j], SdZy3[0, j]])\n",
    "            FES5[i, j] += np.sum([SdZy5[i, 0], -SdZy5[0, 0], -SdZx5[i, j], SdZx5[i, 0]])\n",
    "            FES6[i, j] += np.sum([-SdZx5[0, j], SdZx5[0, 0], SdZy5[i, j], -SdZy5[0, j]])\n",
    "            FES7[i, j] += np.sum([-SdZy7[i, 0], SdZy7[0, 0], -SdZx7[i, j], SdZx7[i, 0]])\n",
    "            FES8[i, j] += np.sum([-SdZx7[0, j], SdZx7[0, 0], -SdZy7[i, j], SdZy7[0, j]])\n",
    "\n",
    "    FES = FES - np.min(FES)\n",
    "    FES2 = FES2 - np.min(FES2)\n",
    "    FES3 = FES3[::-1] - np.min(FES3)\n",
    "    FES4 = FES4[::-1] - np.min(FES4)\n",
    "    FES5 = FES5[:,::-1] - np.min(FES5)\n",
    "    FES6 = FES6[:,::-1] - np.min(FES6)\n",
    "    FES7 = FES7[::-1,::-1] - np.min(FES7)\n",
    "    FES8 = FES8[::-1,::-1] - np.min(FES8)\n",
    "    FES_a = (FES + FES2 + FES3 + FES4 + FES5 + FES6 + FES7 + FES8) / 8\n",
    "    FES_a = FES_a - np.min(FES_a)\n",
    "\n",
    "    return FES_a\n",
    "\n",
    "### Extensive 2D Finite difference method with option to create finer gradients using interpolation\n",
    "\n",
    "def intg_FD8_interpolate(FX,FY, i_bins):\n",
    "\n",
    "    r = np.stack([X.ravel(), Y.ravel()]).T\n",
    "    Sx = interpolate.CloughTocher2DInterpolator(r, FX.ravel())\n",
    "    Sy = interpolate.CloughTocher2DInterpolator(r, FY.ravel())\n",
    "    Nx, Ny = i_bins\n",
    "\n",
    "    x_new = np.linspace(grid.min(), grid.max(), Nx)\n",
    "    y_new = np.linspace(grid.min(), grid.max(), Ny)\n",
    "    X_new, Y_new = np.meshgrid(x_new, y_new)\n",
    "\n",
    "    ri = np.stack([X_new.ravel(), Y_new.ravel()]).T\n",
    "    FX = Sx(ri).reshape(X_new.shape)\n",
    "    FY = Sy(ri).reshape(Y_new.shape)\n",
    "\n",
    "    grid_diff = np.diff(x_new)[0]\n",
    "\n",
    "\n",
    "    SdZx = np.cumsum(FX, axis=1) * grid_diff  # cumulative sum along x-axis\n",
    "    SdZy = np.cumsum(FY, axis=0) * grid_diff  # cumulative sum along y-axis\n",
    "    SdZx3 = np.cumsum(FX[::-1], axis=1) * grid_diff  # cumulative sum along x-axis\n",
    "    SdZy3 = np.cumsum(FY[::-1], axis=0) * grid_diff  # cumulative sum along y-axis\n",
    "    SdZx5 = np.cumsum(FX[:, ::-1], axis=1) * grid_diff  # cumulative sum along x-axis\n",
    "    SdZy5 = np.cumsum(FY[:, ::-1], axis=0) * grid_diff  # cumulative sum along y-axis\n",
    "    SdZx7 = np.cumsum(FX[::-1, ::-1], axis=1) * grid_diff  # cumulative sum along x-axis\n",
    "    SdZy7 = np.cumsum(FY[::-1, ::-1], axis=0) * grid_diff  # cumulative sum along y-axis\n",
    "\n",
    "\n",
    "    FES = np.zeros(i_bins)\n",
    "    FES2 = np.zeros(i_bins)\n",
    "    FES3 = np.zeros(i_bins)\n",
    "    FES4 = np.zeros(i_bins)\n",
    "    FES5 = np.zeros(i_bins)\n",
    "    FES6 = np.zeros(i_bins)\n",
    "    FES7 = np.zeros(i_bins)\n",
    "    FES8 = np.zeros(i_bins)\n",
    "\n",
    "    for i in range(FES.shape[0]):\n",
    "        for j in range(FES.shape[1]):\n",
    "            FES[i, j]  += np.sum([SdZy[i, 0], -SdZy[0, 0], SdZx[i, j], -SdZx[i, 0]])\n",
    "            FES2[i, j] += np.sum([SdZx[0, j], -SdZx[0, 0], SdZy[i, j], -SdZy[0, j]])\n",
    "            FES3[i, j] += np.sum([-SdZy3[i, 0], SdZy3[0, 0], SdZx3[i, j], -SdZx3[i, 0]])\n",
    "            FES4[i, j] += np.sum([SdZx3[0, j], -SdZx3[0, 0], -SdZy3[i, j], SdZy3[0, j]])\n",
    "            FES5[i, j] += np.sum([SdZy5[i, 0], -SdZy5[0, 0], -SdZx5[i, j], SdZx5[i, 0]])\n",
    "            FES6[i, j] += np.sum([-SdZx5[0, j], SdZx5[0, 0], SdZy5[i, j], -SdZy5[0, j]])\n",
    "            FES7[i, j] += np.sum([-SdZy7[i, 0], SdZy7[0, 0], -SdZx7[i, j], SdZx7[i, 0]])\n",
    "            FES8[i, j] += np.sum([-SdZx7[0, j], SdZx7[0, 0], -SdZy7[i, j], SdZy7[0, j]])\n",
    "\n",
    "    FES = FES - np.min(FES)\n",
    "    FES2 = FES2 - np.min(FES2)\n",
    "    FES3 = FES3[::-1] - np.min(FES3)\n",
    "    FES4 = FES4[::-1] - np.min(FES4)\n",
    "    FES5 = FES5[:,::-1] - np.min(FES5)\n",
    "    FES6 = FES6[:,::-1] - np.min(FES6)\n",
    "    FES7 = FES7[::-1,::-1] - np.min(FES7)\n",
    "    FES8 = FES8[::-1,::-1] - np.min(FES8)\n",
    "    FES_a = (FES + FES2 + FES3 + FES4 + FES5 + FES6 + FES7 + FES8) / 8\n",
    "    FES_a = FES_a - np.min(FES_a)\n",
    "\n",
    "    return (FES_a, X_new, Y_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the average deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average deviation of 1D FES\n",
    "\n",
    "def error_1D(FES):\n",
    "    AD = abs(FES - y)\n",
    "    AAD = sum(AD) / len(AD)\n",
    "    print(\"The AAD of the FES is: \" + str(AAD))\n",
    "    return (AD, AAD)\n",
    "\n",
    "# Calculate average deviation of 1D FES in central region [range_min, range_max]. e.g. [-1.75, 1.75]\n",
    "def error_1D_centre(FES, range_min, range_max):\n",
    "    AD = abs(FES[index(-1.75):index(1.75)+1] - y[index(-1.75):index(1.75)+1])\n",
    "    AAD = sum(AD) / len(AD)\n",
    "    print(\"The AAD of the FES from x=\" + str(range_min) +\" to x=\" + str(range_max) + \" is: \" + str(AAD))\n",
    "    return (AD, AAD)\n",
    "\n",
    "# Calculate average deviation of 2D FES\n",
    "\n",
    "def error_2D(FES):\n",
    "    AD = abs(FES - Z)\n",
    "    AAD = sum(sum(AD))/(nbins**2)\n",
    "    print(\"The AAD of the FES is: \" + str(AAD))\n",
    "    return (AD, AAD)\n",
    "\n",
    "def error_2D_cutoff(FES):\n",
    "    Flim = 25\n",
    "    AD = np.where(FES < Flim, abs(FES - Z), 0)\n",
    "    AAD = sum(sum(AD))/(np.count_nonzero(AD))\n",
    "    print(\"The AAD of the FES is: \" + str(AAD))\n",
    "    print(Flim)\n",
    "    return (AD, AAD)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define indexing\n",
    "def index(position):\n",
    "    return int((position-min_x)//grid_space) + 1\n",
    "\n",
    "def index_plumed(position, min_x, grid_space):\n",
    "    return int((position-min_x)//grid_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn every zero of an array into NaN\n",
    "def zero_to_nan(input_array):\n",
    "    len_x, len_y = np.shape(input_array)\n",
    "    for ii in range(len_x):\n",
    "        for jj in range(len_y):\n",
    "            if input_array[ii][jj] == 0: input_array[ii][jj] = float(\"Nan\")\n",
    "    return input_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
